{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용되는 라이브러리 호출\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(context=\"paper\", font_scale=1.5, rc=None)\n",
    "sns.set(font=\"serif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(TARGET, MODEL, gdf, coords, rf_results):\n",
    "    # 디렉토리 생성 \n",
    "    os.makedirs(f'./results/{TARGET}/', exist_ok=True)\n",
    "\n",
    "    # 엑셀\n",
    "    gdf.to_excel(f'./results/{TARGET}/{TARGET}_{MODEL}3.xlsx', index=False)\n",
    "\n",
    "    # 좌표와 예측값을 포함한 GeoDataFrame 생성\n",
    "    geometry = [Point(xy) for xy in coords]\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry=geometry)\n",
    "\n",
    "    # Shapefile\n",
    "    gdf.to_file(f'./results/{TARGET}/{TARGET}_{MODEL}3.shp')\n",
    "\n",
    "    name_dict = {\"교통사고\": \"Accident\", \"범죄\": \"Crime\"}\n",
    "\n",
    "    # 모델을 저장할 파일 이름\n",
    "    filename = f'./results/{TARGET}/{name_dict[TARGET]}_{MODEL}3.pkl'\n",
    "    # 학습된 모델을 pickle로 저장\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(rf_results, file)\n",
    "\n",
    "    print(f\"모델이 {filename} 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bandwidth(X):\n",
    "    # 대역폭 계산 (커널 밀도 추정 사용)\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=1.0).fit(X)\n",
    "    scores = kde.score_samples(X)\n",
    "    print(f\"대역폭 계산 결과 (일부): {scores[:10]}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 실행 함수\n",
    "def run_model(TARGET, MODEL, PATH_DATA):\n",
    "    print(\"데이터를 로드 중입니다...\")\n",
    "    # GQIS를 통해 전처리한 데이터를 로드\n",
    "    gdf = gpd.read_file(PATH_DATA)\n",
    "    \n",
    "    print(\"종속변수와 독립변수 전처리를 시작합니다...\")\n",
    "    # 종속변수 전처리\n",
    "    y = gdf['EPDO'].values.reshape((-1,1))\n",
    "    print(f\"분석 모델의 종속변수는 'EPDO' 변수입니다.\")\n",
    "\n",
    "    # 독립변수 전처리\n",
    "    X = gdf.drop([\"ROAD_ID\", \"x\", \"y\", \"EPDO\", \"geometry\"], axis=1).values\n",
    "    print(f'학습에 활용되는 특징들은 {gdf.drop([\"ROAD_ID\", \"x\", \"y\", \"EPDO\", \"geometry\"], axis=1).columns.to_list()}입니다.')\n",
    "    print()\n",
    "    \n",
    "    # 좌표 데이터 추출\n",
    "    u = gdf['x']\n",
    "    v = gdf['y']\n",
    "    coords = list(zip(u, v))\n",
    "    \n",
    "    print(\"데이터 스케일링을 진행합니다...\")\n",
    "    # 데이터의 스케일링 (특이 행렬 방지 및 결측값 처리)\n",
    "    X = pd.to_numeric(X.flatten(), errors='coerce').astype(float).reshape(X.shape)\n",
    "    X[X == 0] = np.random.uniform(0, 0.5, size=np.count_nonzero(X == 0))\n",
    "    X[np.isnan(X)] = np.random.uniform(0, 0.5, size=np.count_nonzero(np.isnan(X)))\n",
    "    X = np.round(X, 2)\n",
    "\n",
    "    y = pd.to_numeric(y.flatten(), errors='coerce').astype(float).reshape(y.shape)\n",
    "    y[y == 0] = np.random.uniform(0, 0.5, size=np.count_nonzero(y == 0))\n",
    "    y[np.isnan(y)] = np.random.uniform(0, 0.5, size=np.count_nonzero(np.isnan(y)))\n",
    "    y = np.round(y, 2)\n",
    "\n",
    "    print(\"대역폭 계산을 시작합니다...\")\n",
    "    # 대역폭 계산 (Kernel Density 사용)\n",
    "    gdf['Bandwidth'] = calculate_bandwidth(X)\n",
    "\n",
    "    # 랜덤 포레스트 모델 실행\n",
    "    if MODEL == \"RandomForest\":\n",
    "        print(\"랜덤 포레스트 모델 학습을 시작합니다...\")\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y.ravel())  # 모델 학습\n",
    "        pred_results = model.predict(X)  # 예측값 생성\n",
    "        gdf['RF_Predict'] = pred_results\n",
    "\n",
    "        # R2 점수 계산\n",
    "        r2 = r2_score(y, pred_results)\n",
    "\n",
    "        # AIC와 AICc 계산\n",
    "        residuals = y.ravel() - pred_results\n",
    "        n = len(y)\n",
    "        rss = np.sum(residuals**2)\n",
    "        sigma2 = rss / n\n",
    "        log_likelihood = -0.5 * n * (np.log(2 * np.pi * sigma2) + 1)\n",
    "\n",
    "        k = model.n_estimators  # 트리 개수를 자유도로 사용\n",
    "        aic = 2 * k - 2 * log_likelihood\n",
    "        aicc = aic + (2 * k * (k + 1)) / (n - k - 1)\n",
    "\n",
    "        # 모델 성능 출력\n",
    "        print(f'랜덤 포레스트 모델의 R2 점수는 {r2}입니다.')\n",
    "        print(f'랜덤 포레스트 모델의 AIC는 {aic}입니다.')\n",
    "        print(f'랜덤 포레스트 모델의 AICc는 {aicc}입니다.')\n",
    "        print()\n",
    "\n",
    "        print(\"결과를 저장합니다...\")\n",
    "        # 결과 저장\n",
    "        save_model(TARGET, MODEL, gdf, coords, model)\n",
    "    else:\n",
    "        # 지원되지 않는 모델 유형일 경우 예외 발생\n",
    "        raise ValueError(f\"지원되지 않는 모델 유형입니다: {MODEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터를 로드 중입니다...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 분석을 수행할 데이터\n",
    "    TARGET = \"교통사고\"\n",
    "\n",
    "    # 분석을 진행할 모델 (RandomForest)\n",
    "    MODEL = \"RandomForest\"\n",
    "\n",
    "    # 분석할 데이터가 저장된 경로\n",
    "    PATH_DATA = r\"C:\\Users\\KDP-27\\Desktop\\KDT6\\mini_project\\제이솔루션\\data2\\최적지 선정 분석 코드(교통사고)\\data\\교통사고_분석_데이터.shp\"\n",
    "    \n",
    "    # 코드 동작 시간 확인\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 대역폭 찾고 모델 구동\n",
    "    run_model(TARGET, MODEL, PATH_DATA)\n",
    "    \n",
    "    print(f\"코드가 동작하는데 걸린 시간은 {str(datetime.timedelta(seconds=int(time.time() - start_time)))}입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
